# --- AI Provider Configuration (Optional) ---
# You can configure LLM providers via Settings UI or set defaults here
# Providers: openai | openrouter | huggingface | rule-based

# Default Provider (if not set in UI)
DEFAULT_AI_PROVIDER=rule-based

# OpenAI (https://platform.openai.com/api-keys)
# Model options: gpt-3.5-turbo (cheap), gpt-4o-mini, gpt-4o
OPENAI_API_KEY=sk-proj-...
DEFAULT_OPENAI_MODEL=gpt-3.5-turbo

# OpenRouter (https://openrouter.ai/keys)
# 50 free requests/day
# Model options: anthropic/claude-3-haiku (recommended, cheap), mistralai/mistral-7b-instruct, google/gemini-flash-1.5
OPENROUTER_API_KEY=sk-or-v1-...
DEFAULT_OPENROUTER_MODEL=anthropic/claude-3-haiku

# Hugging Face (https://huggingface.co/settings/tokens)
# 500 free requests/day  
# Model options: mistralai/Mistral-7B-Instruct-v0.2, meta-llama/Llama-2-7b-chat-hf
HUGGINGFACE_API_KEY=hf_...
DEFAULT_HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# --- SECURITY NOTE ---
# The Settings UI allows storing keys in database (aiPolicy.llm field)
# This is convenient but less secure. For production, use ENV vars above.
# If both are set, UI settings take precedence.
